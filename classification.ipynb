{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric and plotting libraries\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning/vision libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if it's available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 region, all info about speakers, 4 sessions, white noise, 50 info per neuron (per speaker), 100 neurons per region => image 100x250(5x50) - 8 of them (2 states x 4 sessions) x 30 (sampling points over time)\n",
    "- final 240 images (120 per state)\n",
    "- oversampling input images with NaNs (maybe random oversampling)\n",
    "- combination of 2 different regions in one image/mice???\n",
    "- including bandpass noise into data representation \n",
    "- representing input images as different stimulus (100 x 50)\n",
    "---\n",
    "- training on combined sessions, different sessions (evaluating results on different sessions)\n",
    "- maybe training on the particular stimulus and then seeing wich stimulus is the most inforative for the state classification\n",
    "- performing classification on different regions to see which region (to see if some regions have very noninformative responses)\n",
    "- performin classification on different combination of regions???\n",
    "- comparing the classificator performance - input data is white noise/bandpass noise/combination of noises\n",
    "---\n",
    "- stimulus classificators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification between anest and awake state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucitavanje_podataka(directory):\n",
    "    id = 0\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        label = f.split(\"\\\\\")[-1][0:2]\n",
    "        id = id + 1\n",
    "        dat = np.load(f)\n",
    "        data.append([id, dat, label])\n",
    "    \n",
    "    random.seed(2)\n",
    "    random.shuffle(data)\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vektorizacija(podaci):\n",
    "    prevodjenje_labela = {\"an\": [1], \"aw\": [0]}  # TRUE:Mirtrons  FALSE:canonical microRN\n",
    "\n",
    "    vektorizovani_podaci = []\n",
    "    for a in podaci:\n",
    "        vektorizovani_podaci.append([a[0], a[1], prevodjenje_labela[a[2]]])\n",
    "\n",
    "    return vektorizovani_podaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def podela_podataka(data_vectors):\n",
    "    X_train, y_train, X_test, y_test = [],[],[],[]\n",
    "    i,j = 0,0\n",
    "\n",
    "    random.shuffle(data_vectors)\n",
    "    for item in data_vectors:\n",
    "        if item[2]==[1]:\n",
    "            i = i + 1\n",
    "            if i <= 50:\n",
    "                X_test.append(item[1])\n",
    "                y_test.append(item[2])\n",
    "            else:\n",
    "                X_train.append(item[1])\n",
    "                y_train.append(item[2])\n",
    "        else:\n",
    "            j = j + 1\n",
    "            if  j<= 50:\n",
    "                X_test.append(item[1])\n",
    "                y_test.append(item[2])\n",
    "            else:\n",
    "                X_train.append(item[1])\n",
    "                y_train.append(item[2])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "putanja = r\"C:\\Users\\m.nedeljkovic\\Desktop\\cnn data\\data\"\n",
    "#niz od podataka za svaku sekvencu (podatak je niz od id-ja, sekvence i labele)\n",
    "podaci = ucitavanje_podataka(putanja)\n",
    "\n",
    "vektorizovani_podaci = vektorizacija(podaci)\n",
    "X_train, y_train, X_test, y_test = podela_podataka(vektorizovani_podaci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(300, 1, 110, 155)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test).reshape(100, 1, 110, 155)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test[:20]\n",
    "y_test2 = y_test[:20]\n",
    "\n",
    "X_test1 = X_test[20:]\n",
    "y_test1 = y_test[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "savеpath = \"C:/Users/m.nedeljkovic/Desktop/cnn data/\"\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    np.save(savеpath + 'train/' + str(y_train[i][0]) + '/' + str(i) + '.npy', X_train[i])\n",
    "\n",
    "for i in range(len(X_test1)):\n",
    "    with open(savеpath + 'val/' + str(y_test1[i][0]) + '/' + str(i) + '.npy', 'wb') as f:\n",
    "        np.save(f, X_test1[i])\n",
    "\n",
    "for i in range(len(X_test2)):\n",
    "    with open(savеpath + 'test/' + str(y_test2[i][0]) + '/' + str(i) + '.npy', 'wb') as f:\n",
    "        np.save(f, X_test2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 16  # batch size of input\n",
    "\n",
    "# CONV_SIZE = 3    #first filter size\n",
    "# CONV_DEEP = 128   #number of first filter(convolution deepth)\n",
    "\n",
    "DROPOUT_KEEP_PROB = 0.5  # keep probability of dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_numpy_list, data_transforms):\n",
    "        self.data_numpy_list = data_numpy_list\n",
    "        self.transform = data_transforms\n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        for ind in range(len(self.data_numpy_list)):\n",
    "            data_slice_file_name = self.data_numpy_list[ind]\n",
    "            data_i = np.load(data_slice_file_name)\n",
    "            idx = data_slice_file_name.rfind(\"\\\\\")\n",
    "            self.data_list.append(data_i)\n",
    "            self.label_list.append(int(data_slice_file_name[idx-1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        data = np.asarray(self.data_list[index])\n",
    "        label = np.asarray(self.label_list[index])\n",
    "        data = torch.from_numpy(data)\n",
    "        label = torch.from_numpy(label)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_numpy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder\n",
    "class CustomCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 3), stride=1)\n",
    "        self.conv2 = nn.Conv2d(16, 64, (3, 3), stride=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3, 3), stride=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, (3, 3), stride=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, (3, 3), stride=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, (3, 3), stride=1)\n",
    "        self.conv7 = nn.Conv2d(256, 512, (3, 3), stride=1)\n",
    "        self.conv8 = nn.Conv2d(512, 512, (3, 3), stride=1)\n",
    "\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        self.norm5 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d((2, 2))\n",
    "      \n",
    "        self.fc1 = nn.Linear(4096, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 64)\n",
    "       \n",
    "\n",
    "        self.sf = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        y1 = self.conv1(x)\n",
    "        y1 = self.norm1(y1)\n",
    "        y2 = self.conv2(y1)\n",
    "        y3 = self.maxpool(y2)\n",
    "        y4 = self.conv3(y3)\n",
    "        y4 = self.norm3(y4)\n",
    "        y5 = self.conv4(y4)\n",
    "        y6 = self.maxpool(y5)\n",
    "        y7 = self.conv5(y6)\n",
    "        y7 = self.norm4(y7)\n",
    "        y8 = self.conv6(y7)\n",
    "        y9 = self.maxpool(y8)\n",
    "        y10 = self.conv7(y9)\n",
    "        y11 = self.conv8(y10)\n",
    "        y12 = self.conv8(y11)\n",
    "        y13 = self.maxpool(y12)\n",
    "        y14 = torch.flatten(y13, 1)\n",
    "        y15 = self.fc1(y14)\n",
    "        y16 = self.fc2(y15)\n",
    "        y17 = self.fc3(y16)\n",
    "        y = self.sf(y17)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs, path, dataloaders):\n",
    "    start_time = time.time()\n",
    "\n",
    "    metrics = defaultdict(list)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            best_acc = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels.long())\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    if(preds[i] == labels.data[i]):\n",
    "                        if(preds[i] == 1):\n",
    "                            tp += 1\n",
    "                        else:\n",
    "                            tn += 1\n",
    "                    else:\n",
    "                        if (preds[i] == 1):\n",
    "                            fp += 1\n",
    "                        else:\n",
    "                            fn += 1\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (preds == labels.data).sum()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_acc = 100 * float(correct) / total\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "\n",
    "            metrics[phase + \"_loss\"].append(epoch_loss)\n",
    "            metrics[phase + \"_acc\"].append(epoch_acc)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training complete in {(time_elapsed // 60):.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc: .4f}')\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = 2 * tp / (2 * tp + fp + fn)\n",
    "    print(f'Sens: {sensitivity: .4f} Spec: {specificity: .4f} F1: {f1: .4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), path)\n",
    "    # load best model weights\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, criterion ,optimizer, PATH, podaci):\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    phase = 'test'\n",
    "    for inputs, labels in podaci[phase]:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "        for i in range(len(preds)):\n",
    "            if (preds[i] == labels.data[i]):\n",
    "                if (preds[i] == 1):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if (preds[i] == 1):\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels.data).sum()\n",
    "\n",
    "    epoch_loss = running_loss / 201\n",
    "    epoch_acc = 100 * float(correct) / total\n",
    "    mcc = (tn * tp-fp*fn) / math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)) \n",
    "    print(f'MCC: {mcc: .4f}')\n",
    "    print(f'Test Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return epoch_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params in model 9411008\n",
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.0000\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.4412\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.5660\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.6250\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.6593\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.6818\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.6977\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7095\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7186\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7258\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7317\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7366\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7407\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7443\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7473\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7500\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7524\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7544\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7563\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7580\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7595\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: nan Acc: 50.7609\n",
      "val Loss: nan Acc: 50.7895\n",
      "Epoch 22/99\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Marija\\noise correlation\\LMU_neuroscience\\classification.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=44'>45</a>\u001b[0m optimizer_conv \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39mrequires_grad, custom_cnn\u001b[39m.\u001b[39mparameters()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumber of params in model \u001b[39m\u001b[39m{\u001b[39;00mcount_parameters(custom_cnn)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=47'>48</a>\u001b[0m model_conv, metrics \u001b[39m=\u001b[39m train_model(custom_cnn, criterion, optimizer_conv, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, path\u001b[39m=\u001b[39;49mpath1, dataloaders\u001b[39m=\u001b[39;49mdataloaders)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=49'>50</a>\u001b[0m train_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(metrics[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=50'>51</a>\u001b[0m val_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(metrics[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32md:\\Marija\\noise correlation\\LMU_neuroscience\\classification.ipynb Cell 30\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs, path, dataloaders)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=33'>34</a>\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=34'>35</a>\u001b[0m \u001b[39m# track history if only in train\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=35'>36</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=36'>37</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=37'>38</a>\u001b[0m     _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=39'>40</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mlong())\n",
      "File \u001b[1;32mc:\\Users\\m.nedeljkovic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\Marija\\noise correlation\\LMU_neuroscience\\classification.ipynb Cell 30\u001b[0m in \u001b[0;36mCustomCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=35'>36</a>\u001b[0m y2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(y1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=36'>37</a>\u001b[0m y3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(y2)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=37'>38</a>\u001b[0m y4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(y3)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=38'>39</a>\u001b[0m y4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(y4)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Marija/noise%20correlation/LMU_neuroscience/classification.ipynb#ch0000021?line=39'>40</a>\u001b[0m y5 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(y4)\n",
      "File \u001b[1;32mc:\\Users\\m.nedeljkovic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\m.nedeljkovic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\m.nedeljkovic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    putanja = \"C:/Users/m.nedeljkovic/Desktop/cnn data/data\"\n",
    "    #niz od podataka za svaku sekvencu (podatak je niz od id-ja, sekvence i labele)\n",
    "    podaci = ucitavanje_podataka(putanja)\n",
    "\n",
    "    vektorizovani_podaci = vektorizacija(podaci)\n",
    "    X_train, y_train, X_test, y_test = podela_podataka(vektorizovani_podaci)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    X_test2 = X_test[:20]\n",
    "    y_test2 = y_test[:20]\n",
    "\n",
    "    X_test1 = X_test[20:]\n",
    "    y_test1 = y_test[20:]\n",
    "\n",
    "    dataset_sizes = {'train': len(X_train),\n",
    "                    'val': len(X_test1),\n",
    "                     'test': len(X_test2)}\n",
    "\n",
    "    dataset = {\n",
    "        'train': [X_train, y_train],\n",
    "        'val': [X_test, y_test]\n",
    "    }\n",
    "\n",
    "    data_dir = \"C:/Users/m.nedeljkovic/Desktop/cnn data\"\n",
    "    path1 = \"C:/Users/m.nedeljkovic/Desktop/Model/state_dict_model.pt\"\n",
    "\n",
    "    # basic error checking to check whether you correctly unzipped the dataset into the working directory\n",
    "    assert os.path.exists(data_dir), f'Could not find {data_dir} in working directory {os.getcwd()}n'\n",
    "    dirs_exist = [os.path.exists(os.path.join(data_dir, x)) for x in ['train', 'val']]\n",
    "    assert all(dirs_exist), f'Could not find train/val dirs check if you have train and val directly under {data_dir}.'\n",
    "    data_numpy_list = {}\n",
    "    data_numpy_list['train'] = [x for x in glob.glob(os.path.join(data_dir, 'train/**/*.npy'), recursive=True)]\n",
    "    data_numpy_list['val'] = [x for x in glob.glob(os.path.join(data_dir, 'val/**/*.npy'), recursive=True)]\n",
    "   \n",
    "    # ImageFolder is a PyTorch class - it expects <class1-name>, <class2-name>, ...folders under the root path you give it\n",
    "    datasets = {x: NumpyDataset(data_numpy_list[x], data_transforms) for x in ['train', 'val']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=BATCH_SIZE, shuffle=True) for x in ['train', 'val']}\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    custom_cnn = CustomCNN().to(device)\n",
    "    optimizer_conv = optim.Adam(filter(lambda p: p.requires_grad, custom_cnn.parameters()))\n",
    "\n",
    "    print(f\"number of params in model {count_parameters(custom_cnn)}\")\n",
    "    model_conv, metrics = train_model(custom_cnn, criterion, optimizer_conv, num_epochs=100, path=path1, dataloaders=dataloaders)\n",
    "\n",
    "    train_loss = np.array(metrics['train_loss'])\n",
    "    val_loss = np.array(metrics['val_loss'])\n",
    "    train_acc = np.array(metrics['train_acc'])\n",
    "    val_acc = np.array(metrics['val_acc'])\n",
    "\n",
    "    np.savetxt('train_loss.csv', train_loss, delimiter=',')\n",
    "    np.savetxt('val_loss.csv', val_loss, delimiter=',')\n",
    "    np.savetxt('train_acc.csv', train_acc, delimiter=',')\n",
    "    np.savetxt('val_acc.csv', val_acc, delimiter=',')\n",
    "\n",
    "    podaci_za_test = [x for x in glob.glob(os.path.join(data_dir, 'test/**/*.npy'), recursive=True)]\n",
    "    datasets1 = {x: NumpyDataset(podaci_za_test, data_transforms) for x in ['test']}\n",
    "    podaci = {x: torch.utils.data.DataLoader(datasets1[x], batch_size=BATCH_SIZE, shuffle=True) for x in\n",
    "              ['test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3ff55a2362d840d3433b3a68631efa6e477163e310b6a9fd17f9078908dbfa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
